# Zeze-关于缓存和乐观锁

写了篇关于Zeze-服务器框架的探讨，有同学建议对每个子标题展开讨论，就试试。

这篇文章将以Zeze.Transaction.TableCache为蓝本来讨论，由于时间过了很久，
不保证跟当前代码完全一致。另外这篇主要讲缓存，但是也会涉及一点其他技术，
比如分布式，多线程，锁定和乐观锁等。另外以下提到缓存都是特指TableCache，
除非特别说明。

Zeze也可以说是一个KV数据库，每个表可以看作一个Map，每个表的缓存也用
一个Map进行管理。

## 缓存基础
缓存不是数据的拥有者，首先需要考虑装载，保存，卸载，分布式同步。
* 装载采用同步方式，不存在的时候，访问线程同步的等待从后端数据库装载。
* 保存默认为定时方式，可以配置部分表为重要的，修改后马上保存。由于Zeze实际上
基于事务，效果是一个事务里面的修改涉及重要的表，那么这个事务的修改就会被马上
保存。马上保存也有个全局选项，所有的修改都马上保存。考虑效率，不建议开启这个
全局选项。
* 卸载采用Lru方式，超过缓存容量以后，最老的未访问的记录会被优先卸载。当然
脏记录肯定不会被卸载，所有应用如果遍历修改大量的记录，缓存容量有可能超过配置。
* 分布式同步。这是分布式的核心，“Zeze是一个基于一致性缓存的分布式事务
应用框架”，这句Zeze的总体描述已经体现了这一点。这篇文章先不展开讨论了。

## 缓存的并发优化
普通的Lru维护了最近访问队列，这个队列导致它需要一把锁进行互斥。所以java的Lru实现
java.util.LinkedHashMap有这把锁。这导致一个问题，如果应用的热点非常集中，大量的
并发请求都访问同一张表，即同一个缓存，那么并发能力就上不去。找了很久都没有找到现成
的并发Lru实现，最终自己实现了一个Zeze.Util.ConcurrentLruLike。TableCache跟它几乎
一样，只是作为Zeze的核心存储，做了一些内存优化，单独再次实现了一次。TableCache
可以看作专用的ConcurrentLruLike。为了名字更好听，下面都用ConcurrentLruLike这个名字。

ConcurrentLruLike的并发能力基础是java.util.concurrent.ConcurrentHashMap，并不是自己
实现的。这里说明一下这个Lru能并发的原理，秘密就是Like。因为它不使用一个队列，而是一个
节点（用ConcurrentHashMap实现）队列。最近使用的记录保存在热点节点中，定时产生新的
节点，并把热点节点推到节点队列中。这样整个节点队列就是从新到老排列的，当要实现Lru删除
功能时，从最老的节点里面访问并卸载记录。当然记录需要维护自己在哪个节点中，这样记录访问
的时候，就需要从老的节点中删除，并加入热点节点。由于每个节点都是ConcurrentHashMap，
所有的访问都是并发的，但是由于没有维护单一的记录队列，而是节点队列，所以它不是精确的Lru，
而是“Like”。但终于使得所有记录的访问都能并发起来。

这个实现的缺点是，一次缓存的数据访问操作，会带来维护节点两次Map操作。有一点浪费CPU。
总的思想是，宁可浪费一点CPU，也要能并发，不堵在一把锁上。这两次Map操作在整个事务中的
占比应该不会很大，没有仔细分析过，只是想象的。最后现在的机器使用情况来看，一般CPU是
富余的，浪费点就浪费点吧。并发优先！

实际上，不是很满意这个ConcurrentLruLike的实现方式，以后找到更好的方法，再来优化它。

## 缓存容量配置和本地硬盘的二级缓存
由于应用的记录大小差异肯定很大，而内存总是有限的，又要考虑增加缓存容量，提高缓存命中率。
这个缓存容量的配置会成为一个比较大的负担。综合考虑，Zeze的记录采用了SoftReference，在
系统内存不是很充足时，会把数据保存到本地硬盘中，实现了二级缓存。这里每个记录的存根，包含
的key还是存在内存中的，只有value部分被降级。有了二级缓存，就能比较轻松的提高缓存容量的配置，
也能简化配置压力，因为内存中的数据和记录大小无关了。

这个功能运转还算稳定，但要注意它的疗效没有定量分析过，到底带来多少好处未知。

## 多线程、缓存的记录锁和乐观锁
Zeze的锁定单位是记录，每个KV就是一个记录。当多线程访问的时候，是需要加锁的。很显然，
如果访问一个加一个锁，由于访问的记录顺序无法预测，最终结果肯定导致死锁。为了解决死锁
问题，Zeze采用了乐观锁算法。事务执行过程中不加锁，所有修改仅当前事务可见。提交的时候
对所有访问的记录排序 并且加锁并进行冲突检查。这里不死锁的关键就是排序加锁，也不是什么
高级东西。

* 乐观锁并发的原理

事务内所有访问（读写）的记录在冲突检查时需要确保Timestamp没有变化。事务成功时， 相当于
独占所访问的记录。这个并发策略是严格，但显然是正确的。 乐观锁算法要点

1. 排序加锁，实际上所访问的记录存储在SortedDictionary中。
2. 加锁后检查冲突，即数据是否改变。冲突则重做事务。
3. 冲突重做时保持已经得到的锁，这样在冲突非常严重时，第二次执行事务一般都能成功，而
不会陷入一直冲突，事务永远没法完成的情况。
4. 重做保持锁，但重做过程中所访问的记录可能发生变化，所以重做仍然需要再次执行 
lockAndCheck逻辑，并且处理所访问的记录发生变更的问题。
5. 逻辑处理返回错误码或者异常时也需要检查lockAndCheck，因为乐观锁在实际处理逻辑时
没有加锁，可能存在并发原因导致本来不应该发生逻辑错误，此时的仍然需要加锁并完成冲 突检查，
如果冲突了，也需要重做。

