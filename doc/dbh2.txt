dbh2
	或者叫dbh2，不依赖db.h，这个名字有纪念意义。
	rocksdb桶：部分表，部分key。
	桶的管理和分配。关键！
	桶的raft。
	并发：zeze专用，无需复杂并发控制。或者几乎不需要？
	使用c++？【第一版还是java，以后真有用处，并且找到人，再转成c++】
	raft c++？
	c++ net？wepoll

Database
	每个Database包含多张表。
	多Database。

Table
	kv表

Bucket
	每个kv表按一定规则分到不同的桶里面。
	每个桶由raft节点组成。

Bucket-Route
	kv划分规则：1. sort；2. hash

Bucket-Route-Sort
	需要一个有顺序按段划分byte[]的算法。关键问题是划分段多大。下面的方法能工作。
	现在考虑到的方法是动态规划路由：一开始一个桶，容量超过了，就从现有的记录数量中间拆分成两个。
	然后两个桶来用。等到其中一个桶又超出了，再拆分。暂不考虑合并桶（删除是少见的）。

Bucket-Route-Hash（第一版不实现）
	一致性hash算法。
	当桶增加时，需要能感知需要迁移的桶。
	现在Zeze采用的一个最常用的算法，可以继续采用，但是由于感知迁移桶的需求，
	不能使用虚拟节点。暂时考虑的策略是，一开始就建立足够数量桶（节点）。

Bucket-Hot-Split(Sort)
	热点桶二分法拆分，规则和Bucket-Route-Sort一样。

进程
	MasterService，
	DatabaseService，
	Agent，嵌入到dbh2的客户端内执行，
	AgentService，把Agent的功能包装成服务，无状态的dbh2链接机器，用来提高事务安全性，因为嵌入式受应用影响，可能不够安全。
		AgentService 可以解决commit中途挂掉。RocksDb Sync。先Commit，后在事务Id的相关桶里面记录。
		DatabaseService需要能识别出重复的Commit并忽略。
		有了事务提交中途落地状态，AgentService可以省掉。

===============================================================
问题
===============================================================
1. 两段式事务。
根本支持来自RocksDb；下面的逻辑在Agent中执行。
var transList = new list(); // 维护当前事务需要访问的所有Database的事务实例。
foreach (var key in keys)
{
	var dbInfo = Master.Query(key); // 为了性能，需要cache，问题？cache更新以及最终用目标Database主动报错。
	var conn = Dababase.getOrAdd(out maybe transList, dbInfo); // 查询或新建连接，第一次建立链接需要创建事务。
	conn.executeUpdate(key, value);
}
foreach (var trans in transList)
{
	trans.commit();
}

2. 事务并发。
上面的事务是多记录写，读取总是一个事务读取一条记录。对于读写并发，RocksDb已经保证了基本的并发。
其他多记录写的事务并发由Zeze解决。Zeze保证所有的写事务之间没有交集。
所以！本系统不需要任何并发控制。【桶的迁移是一个需要锁并且等待的操作，这个待定】

3.Raft怎么接入
a) RocksDb+Batch
    事务操作记录在Batch里面，提交的时候，发送整个Batch给Raft。
    已经是提交步骤，此时Raft.AppendLog，RocksDb.WriteBatch两步都不能失败。
    可靠性感觉差一点。
    还有个缺点，Batch搜集操作的机器宕机，事务将直接失败，没有利用上Raft集群提供的高可靠能力。

b) OptimisticTransactionDB+Transaction
    事务从开始到结束都同时进行Raft同步。如：BeginTransactionLog, PutLog, DeleteLog, RollbackTransactionLog, CommitTransactionLog。
    当事务提交时，也要求Transaction.Commit, Raft.AppendLog(CommitTransactionLog)这两步不能失败。
    相比a)版本的两步，这两步感觉可靠性稍好些。
    另外没有Leader宕机，事务即失败的问题。可以利用上Raft高可靠集群能力。
    AutoRollback：当事务操作日志系列没有正常结束(Rollback,Commit)，超时以后自动Rollback。
    这个能解决Raft.AppendLog(RollbackLog)丢失问题。
    但是还存在一个问题，即上面提交时要求Commit不能丢失(没有达到多数)问题。如果这个Commit没有回退，
    即一般情况下，没有得到多数票的日志在系统恢复时，存在最新的日志的节点被选为Leader，Commit最终会被正确处理。
    但是，例子：3个节点，Leader1.Append, Node2.Down, Node3.Down，系统恢复，Leader1.Down, Node2 Or Node3 被选为新Leader。
    此时Leader1最后写的日志会被回滚（忘了名词了）。这种情况最危险，会被AutoRollback认为事务回滚，但其他桶是Commit模式。
    看看这个问题怎么解决？
    raft.beginTransaction();
    raft.put ...
    raft.delete ...
    prepareCommit(); // 此时持久化一个日志。带上全局唯一（可以弱一些，还没细想）transactionId
    raft.commit // 此时这个可以丢失了。
    AutoRollback的时候检查prepareCommit日志集合，发现存在变成AutoCommit。
    还有个问题：autorollback对于rollback，设置超时没问题，对于autocommit，超时是不行的，
    此时后续的transaction可能已经commit，事务操作的记录的相关性在zeze内处理，但是时序是
    需要保证的，autocommit导致时序错乱是个问题
    继续补丁：raft系统恢复的时候，被选为leader的节点准备阶段（有这个）增加一个步骤，对于log.apply好以后
    还存在的transaction马上做preparecommit判断，马上决定好该怎么处理。都处理完了以后，才开始服务。
    prepare commit有好处，但还是带来一个问题，因为查询虽然简单，但还是涉及系统可用性问题，就是
    把raft已经解决的问题换了一个。有价值但还要看怎么处理
    【error commit】
    preparecommit由于查询问题，看来基本废弃了。可以参考这个思路，换个做法。先回到commit必须成功这个定义。
    commit失败肯定由于某个桶的raft发生了多数宕机。改成此时记录失败的commit的事务，这样记录的就很小。然后
    再考虑这个记录怎么给新恢复的raft桶选出leader时用来继续commit。由于新的方法记录会很小，更容易分发和使用。
    不过有点换汤不换药的感觉。
    【error commit 分发】
    agent：
         foreach (var t in trans)
              t.CommitAsync();
         foreach (var tt in commit_timeout_trans)
              tt.BroadcastToCurrentAliveRaftNode();
     raft new leader:
         foreach (var t in transNotClosed)
              if (t is commit_timeout_trans)
                  t.commit(); // 继续commit；
              else
                   t.rollbackDelay(); // 其他没有closed的事务默认都是延迟一定时间以后rollback，就是AutoRollback，这个处理的情况比较多。
      question: 
          broadcast 比 new leader 晚到。
          需要设置发现事务commit超时小于选举的时间。小的多些，上面的分发就比较可靠了。
          这个做法有点raft机制的味道。
          灾难：broadcast没有送达。
      分发问题可以继续，暂停一下。

4. 桶按key排序分段，写入是怎么提高并发。
    hash方式看起来具有极大的并发写入速度。

5.并发walk，同时向不同的DatabaseService发送walk请求。归并（按顺序？）

6.MapReduce。

7. Bucket-Split需求
	记录级别并发拆分：正在迁移的记录的访问需要等待。其他并发。
	问题要点：
	已经迁移完成的正常访问，迁移未完成按老的方式访问，这两种是否存在什么问题。
	算法思路要点：
	[1,2,3,4,5,6,7,8,9]
	[1,2,3,4,5] [6之后并发迁移到新的桶。]
	            [6,7*] 假设当前迁移记录是7.
	void access(key)
	{
		var bucket = route(key);
		if (bucket.moving)
		{
			// 【实际上下面没有考虑真正的锁定关系，纯伪码】
			var movingkey; // 7
			if (key < movingkey)
				bucket.normalAccess;
			if (key == movingkey) {
				wait;
				bucket.normalAccess;
			}
			bucket.oldbucket.normalAccess; // oldbucket 是拆分前的旧桶。
		}
		else
		{
			bucket.normalAccess;
		}
	}

8. 并发分桶
    a) Master维护所有的桶信息，分桶完成之前，不会route的目标桶。
    b) Master拥有正在进行分桶的信息，目前看来，仅仅用来监控。
    c) 正在进行分桶的服务器维护记录锁（本进程即可）。
    d) 所有桶数据操作使用锁如下：
    Bucket.Get() {
	lock();
	return data.copy();
	unlock();
    }
    Bucket.Transaction(): 
	putOrDelete() {
		lockAndAddTo(trans); // 事务中操作的key锁住，此时分桶操作等待事务完成。
		rocksdb.putOrDelete();
	}
	commit() {
		rocksdb.commit();
		unlockAllLockInTrans();
	}
    Bucket.ConcurrentSplit()	
	{
		var last = srcBucket.last();
		while (last != first) {
			last.lock(); // 一次迁移一条记录。
			moveRecordToDstBucket();
			last.unlock();
		}
	}
     e) Bucket.RouteRedirect()
	上面第7点的补充说明。
	i. 分桶完成之前，master都是返回srcBucket。
	ii. srcBucket判断已经分走，redirect到dst桶。dst桶按上面第d)点执行锁操作
	   虽然目标桶没完全准备好之前，不可能再次被分开，但是锁操作还是统一。
	iii. srcBucket判断的时候需要锁住，对于正在moving的，会等待锁，然后发现已经被moved，然后被redirect。
	iiii. srcBucket判断不会分走的，src桶按上面第d)点执行所操作。
	*. 对于正在moving的记录，有两个事务，会锁柱两个锁。src的，dst的。其中src锁在redirect时可以提前释放掉。

其他细节，不看。

	并发写？
	beginTransaction();
	Transaction { buckets; }
	put(transaction, key, value)
	{
		var bucket = route(key);
		transaction.add(bucket); // 第一次加入Rocks.beginTransaction
		bucket.put(); // 迁移中的参考上面一段。
	}
	delete(key)
	{
		var bucket = route(key);
		transaction.add(bucket); // 第一次加入Rocks.beginTransaction
		bucket.delete(); // 迁移中的参考上面一段。
	}

	Transaction.commit()
	{
		for (var bucket : buckets)
			bucket.commit();
	}

	Bucket
	{
		void put();
		void delete();
		void get();
	}

	并发还是需要锁，模型待定！！！
	? get总是允许读取，由zeze保证系列化。
	？put，delete在事务中，rocks保护get可见性，由zeze保证系列化。
	？剩下的就是迁移中等待（采用bucket本地锁，本地迁移保护，迁移中的记录）
	总的并发：单个记录级别锁定，get访问结束即可释放锁，事务中的等待事务提交才释放锁。
