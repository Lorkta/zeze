打包和更新工具
ConfigEditor 自动完成: Foreign；自动id，Load 的时候记录maxid，以后编辑AddRow都使用这个递增；
ConfigEditor 更多自动完成？普通的列默认最近使用的n个值，根据输入在列中查找最匹配的。
ConfigEditor enum 现在不支持引用在其他文档定义的，有需要了再来加。
----------------------------------------------------------------------------------------------------------------------------------
DatabaseTikv.OperatesTikv
Universe Planet Star
ServiceManager::OfflineNotify 选择目标遍历优化。
ts log?
c# fresh 有bug？
DatabaseDynamoDb 还需测试。
负载均衡；全面审核。
过载保护；更多。

c# 并发比冲突还慢
Benchmark.ABasicSimpleAddOneThread tasks/s=209874.71 time=4.76 cpu=0.00 concurrent=0.00
Benchmark.BBasicSimpleAddConcurrentWithConflict tasks/s=217785.84 time=4.59 cpu=0.00 concurrent=0.00
Benchmark.CBasicSimpleAddConcurrent tasks/s=96997.63 time=10.31 cpu=100.00 concurrent=9.70
Focus Document

Gen 第二次运行才生成 Data
Dbh2 麻雀版跑起来

------------------------------------------------------------------------------------------------------------------------------
2023/3/15 v1.2.0 
------------------------------------------------------------------------------------------------------------------------------
Online.Gropu.serverId不需要，设置这个参数导致需要读取version表，最终导致Linksid重用失效。
Dbh2 麻雀版完成 【待测试】
RocksDb Test key+commit_ts 的查询。
Transaction.Undo ? 【还是没确定方案】

------------------------------------------------------------------------------------------------------------------------------
2023/3/1 v1.1.9 Zeze.Transaction.Data; protocolref import; New Dispatch Protocol For Procedure; Online.sendOneByOne；AutoKey Random
------------------------------------------------------------------------------------------------------------------------------
AutoKeyRandom -> Uuid? 或者纯粹随机？
	考虑冲突的可能，Table增加辅助函数
	Binary insertWithRandomKey(T value) {
		var rKey = randomKey();
		while (!add(rKey, value))
			rKey = randomKey();
		return rKey；
	}
	randomkey 类型选择。
		1. Binary 弄个16字节或更长之类的。减少冲突。
		2. long 8个字节凑合着用？
		3. String 如果用uuid，需要这个类型。否则内部还是long或binary。
Dispatch 也是传参数给事务，需要考虑重置参数问题。@张路
Timer 允许在事件回调里面直接取消。
LinkBroken.Delay 使用Timer（持久化的），防止Logout丢失。Timer中记录LoginVersion。
Online.sendResponse TaskOneByOne 的问题。【如果已经登录则按RoleId排队，没有登录直接发送】
协议处理流程修改：当协议在事务中处理时，重新Decode，达到重置参数的目的。
	旧流程Dispatch在网络线程中执行，对于Rpc.Client很友好。
	新流程Rpc.Handle已经是新的线程了。有一点浪费。
	Find Usage ProtocolFactoryHandle.Handel 检查是否有多余的null判断（新的流程不能判断这个）
	DispatchRpcResponse 不再需要。【考虑改变流程】
	DispatchProtocol2 不再需要
	Protocol.Dispatch恢复，Rpc特别实现它，其实现与Handle差不多。
Timer BUG
Arch BUG
linkd提供给gs查询接口；以及自定义查询-linkd重载的provider service可以增加自定义模块？
	UserIp 传给gs的问题。方案：
	1. ProviderService 自定义模块协议中gs提供保存ip功能，linkd-auth的时候调用并保存。
	2. 在需要访问UserIp的客户端协议中定义变量，linkd拦截这条协议并且填上。
	   需要在linkd引入这条协议，现有的protocolref除了引入还注册进Service。需要选项仅仅引入而不注册。
	   serverdev的linkd知道所有的gs协议，刚好不需要protocolref，但这个方式是几个project生成到common目录达到目的的。有点特殊。
	3. linkd提供ProviderService自定义模块提供查询能力，让gs主动查询。缺点是查询跨进程，延迟较高。
	看看，有什么zeze要做的，
	1. protocolref新参数或者新增protocolref import来表达是一个点。【已实现，import可以定义在任意模块内部】
	2. 其他的都是项目自定义就行了。

Zeze.Transaction.Data Bean的无事务版本。
	-- 没有选择，全部Bean生成完成。
	-- 根据协议配置选择协议依赖的Bean生成Data。
	-- 协议相关生成。
	-- BeanKey. 【不做了】
	-- Bean.assign(Data data).

------------------------------------------------------------------------------------------------------------------------------
2023/2/16 v1.1.8 initRootInfoWithRedo c#; Timer.OfflineNotify; DatagramChannel; Log.TypeId;
------------------------------------------------------------------------------------------------------------------------------
Log.TypeId 方案，主要是模板类型。
	-- Bean增加hashLogMap hashLog专门用来生成模板类型的LogTypeId。
	-- 使用可以继续的hash64方法，和原来的hash32方式【兼容】。
	-- 修改方案，改一个地方算一个：PMap1, 改完！
	-- RocksRaft 改完！
	-- c# 改完。
Zege c# GetPublickUserInfo & encrypt message;
DatagramChannel java
1. UdpServer：DatagramService 1--* DatagramSocket 绑定多个Socket，防止单个Socket超量。
2. UdpClient：DatagramService  1--1 DatagramSession 一一对应。
3. DatagramSession 不能使用PeerInetAddress建立映射，需要逻辑SessionId，这样能允许会话使用过程中端口地址发生变更。
4. DatagramSession创建需要通过服务器验证并分配SessionId。张路建议随机long值（未用）。有一定防止攻击能力。
5. 加密，SessionId不加密+加密（递增SerialId+Data），SerialId使得相同的数据也加密出不一样的结果。
6. 加密重放防止：Session记录当前最大的SerialId和时间，允许比当前SerialId大的包和一小段时间之前的未收到的包。
   一小段时间之前的未收到的包：记录当前时间之前3秒之间的所有SerialId，不处理收到的重复的，小于记录的最小时间的也丢弃。
  加密数据最后加上SessionId用于简单解密验证。
   【这策略有必要吗？】
7. 可靠Udp和加密，【不实现可靠Udp】，实现的话，使用流加密即可。
8. a) 乱序丢弃，这种策略，第6点不需要复杂控制，只需要记录最大的serialId即可。
    b) 允许乱序，
initRootInfoWithRedo c#; @张路
Timer.OfflineNotify

------------------------------------------------------------------------------------------------------------------------------
2023/2/6 v1.1.7 TimeThrottle; Linkd.OverBandwidth; CheckpintFlushMode; AutoKeyAtomic;
------------------------------------------------------------------------------------------------------------------------------
AutoKeyAtomic
	使用ImportantTable记录种子，
	使用另外一个线程执行事务递增种子。
BUG initRootInfoWithRedo 导致isManager失败，最终数据没有保护到。
BUG FlushSet 没有setDirty(false)【已解决】
BUG FLushSet 会出现破坏acid的现象【===============未解决===============】
CheckpintFlushMode 以及相关性能测试。
Mysql halt 程序在没有提交和回滚的情况下，服务器的行为。
过载保护；更多。--- linkd流量过载保护。
	统计LinkdService出入？
	统计ProviderService出入？
	根据配置，达到80%以后就限制某些地方（哪里）？达到90%就更严格限制？
	思路：
	ProviderService的总输入或者LinkdService的总输出达到各自配置值
		80%开始限制客户端部分请求（如Move）,
		90%开始限制所有客户端请求。
	ProviderService,LinkdService统计以后，加拦截点。
	丢弃高层接口：限制丢弃策略接口定义在LinkdApp中。
	丢弃底层接口：丢弃实现必须是底层，怎么让Linkd控制这个丢弃。
	设计：
	a) Service带宽统计，可以得到每秒的速率。getBandwidth();
	b) Service.discard(int moduleId, int protocolId) return true discard protocol，default false。
	c) override LinkdService.discard(int moduleId, int protocolId) {
		//【新修订：实现成忽略ProviderService的带宽过载配置，因为ProviderService的输入最终也会反映到LinkdService的输出。否则这里应该是max(LinkdService.Rate, ProviderService.Rate)】
		var opt = options.getOverBandwidth();
		if (null == opt)
			return false; // disable
		var rate = (double)getBandwitch() / opt;

		// 总控
		if (rate > 0.9)
			return true; // 熔断: discard all，其他级别在回调中处理。
		if (rate < 0.6)
			return false; // 整体负载小于0.6,全部不丢弃

		/*
		对于游戏可以针对【Move协议】使用下面的策略.
		if (moduleId == Map.ModuleId && protocolId == Map.Move.ProtocolId)
			return Zeze.Util.Random.getInstance().nextInt(100) < (int)((rate - 0.6) / 0.3 * 100);
		return false; // 其他协议全部不丢弃，除非达到熔断。
		*/
		if (linkdApp.discardAction != null)
			return linkdApp.discardAction.call(moduleId, protocolId, rate);
	}

TimeThrottle Queue | Counter 限制请求数量和带宽
	linkd对客户端应该限速，比如，限制5秒内最多25个包，这个算法是允许突发。

------------------------------------------------------------------------------------------------------------------------------
2023/1/19 v1.1.6 DelayRemove; LinkedMap; TaskOneByOneByKey; LinkdProvider.ProcessSendRequest Async; RocketMQ; throws Throwable; Acceptor @internal @external Port=0
------------------------------------------------------------------------------------------------------------------------------
BUG DelayRemove 每个Application只需要创建本ServerId的实例。
DelayRemove 增加延迟立即执行任务；
LinkedMap.clear 使用DelayRemove.addJob。
java bench 大大超过 c# 分析: 初步结论是c# async开销很大，在单线程(ABasicSimpleAddOneThread)模式下，开销占比80%。
AsyncSocket 降低Chain.Flush频率。
TaskOneByOneByKey.executeBatch
一、LinkdProvider.ProcessSendRequest
	使用TaskOneByOneByKey.executeCyclicBarrier把发送的任务放到其他线程，减轻Provider的线程压力。
	1. OneByOne比直接写快，减少wakeup负载传递给ProviderService的线程。
	2. 整体操作复杂了，但是cpu交给了其他线程执行。
二、AsyncSocket.send.wakeup 放到其他线程执行。【不实现】
	1. 增加了整体复杂读，减轻直接调用者的开销。增加了一次线程唤醒的开销。
RocketMQ;
throws Exception 替换 throws Throwable。部分catch(Throwable)修改为catch(Exception)
ServiceConf.Acceptor ip="@internal" "@external"
Acceptor.Port == 0 允许随机选择端口。需要改动：等到bind之后，读出正确的端口，并修改外面的需要注册到ServiceManager的配置。

------------------------------------------------------------------------------------------------------------------------------
2023/1/13 v1.1.5 TaskOneByOneByKey Performance; CommandConsole; Task; Table.walkDesc; New Handshake;
------------------------------------------------------------------------------------------------------------------------------
TaskOneByOneByKey 一次提交一批给Executor执行。减少锁的开销。
Benchmark Encrypt/Decrypt 250M/250M Compress/Decompress 90M/100M
CommandConsole
Task
Table.walkDesc descendingMap.tailMap是什么。
新的Handshake协商流程。doc/handshake.txt
	1. new java-new java Ok
	2. old c# - new java Ok
	3. 需要确认确实启用了加密，压缩之类的。Ok
	4. new c# - new java Ok
	5. encrypt no; compress mppc Ok

【2022/12/28】

------------------------------------------------------------------------------------------------------------------------------
v1.1.4 ProviderDirectService.WaitDirectServerReady; Timer cancelAlways; ServiceManagerWithRaft; 
------------------------------------------------------------------------------------------------------------------------------
【全面】升级Zeze到serverdev
	2. 全面升级Arch。@张路
	   主要流程测试。
	   比如，linkd的Netty【可选的】换成Zeze.Netty（gs.online可能需要点改动。
	   下周开始启动？
ServiceManagerWithRaft 测试
Timer.cancel 无法redirect时，直接从db中cancel掉。
ProviderDirectService.WaitDirectServerReady

【2022/12/21】

------------------------------------------------------------------------------------------------------------------------------
v1.1.3 ServiceManagerWithRaft; BUG BeginSavepoint; 
------------------------------------------------------------------------------------------------------------------------------
Global所有版本AchillesHeelDaemon不再总是记录log，仅仅记录有释放锁的session的日志。
New RocksRaft.Table.selectDirty(); 没有仔细考虑。
ServiceManagerWithRaft
	1. 大锁内处理所有rpc和Rpc结果（单线程）；
	2. 原来的ServiceManager只需要一个网络(Service)配置，新加WithRaft以后怎么配置和选择
【全面】升级Zeze到serverdev
	1. 不兼容协议编码升级。@张路
	   测试客户端登陆通过即可。
	   难点是所有的客户端版本都需要升级一次。
	   本周启动。
BUG 1. LogOne LogDynamic BeginSavepoint EndSavepoint 遗漏；
    2. LogXXX 大部分 BeginSavepoint 复制时遗漏 dup.This = This；
确认：GlobalCacheManagerWithRaft Recude 需要 TransactionLevel="Serializable" ?【不需要】

------------------------------------------------------------------------------------------------------------------------------
tag v1.1.2 Multi-Selectors; Zeze.Net.OutputBuffer; SortedMap; ConsistentHash;
------------------------------------------------------------------------------------------------------------------------------
可以自建Selectors实例，并设置到Service中，使得Service中新建连接使用设置的Selectors。
java::Zeze.Net.OutputBuffer @张路
	合并协议到固定的buffer中，以后才调用jdk.writes。
	加密操作的输出可以直接定向到新的outputbuffer中。
ServiceConfig.maxConnections 限制服务最大连接数量。
SortedMap 基于ArrayList的排序映射。
一致性hash；基于SortedMap

【2022/11/29】
------------------------------------------------------------------------------------------------------------------------------
tag v1.1.1 DatabaseDynamoDb; Database.SetInuse; Table SQL-Type; Table Walk Page; Task ...;
------------------------------------------------------------------------------------------------------------------------------
DatabaseDynamoDb 还需测试。
Database.Operates.SetInuse 总是Clear的代码改成使用系统属性参数。
Daemon 杀掉重启Server设置ClearInuse的参数。
Table key,value都定义成VARBINARY(eMaxKeyLength)。
Table.WalkPage
	@return K lastKey
	K Walk(K exclusiveStartKey, int proposeLimit, TableWalkHandle<K, V> handle)
	K WalkKey(...)

------------------------------------------------------------------------------------------------------------------------------
tag v1.1.0 TableDynamic; Zege ...; Task ...;
------------------------------------------------------------------------------------------------------------------------------
Zege Add Friend
	* 总则：双向好友，可以从一方的状态推测对方状态。
	* 操作：Invite-Accept-Deny-Expire；Remove；
	* 状态：Invite,Normal,Deny,Remove,(None)
		(None) 表示数据不存在。
TableDynamic

------------------------------------------------------------------------------------------------------------------------------
tag v1.0.9 Task ...; MappingClass(dynamic); Overload(java); Variable Bean Set; Druid; Zege ...;
------------------------------------------------------------------------------------------------------------------------------
Task & Achievement & Statistics @项洋呈
(java)Dbcp -> Druid
Bean.setBean CollOne<> LogOne<>
Linkd 过载保护，响应rpc.request和报告错误。
Zeze 过载保护。1. 负载报告完成；2. 负载分配。
Zeze.Net.FamilyClass 增加FamilyClass，中间转发服务（如Linkd）可用来区分Protocol和Rpc，
	顺便加入压缩Protocol.ResultCode,Rpc.IsRequest的能力。
Zege Notify Module Added
gen.exe dynamic 到类继承的映射。
	类实例的数据关联到table.bean，不能保存实例，每次使用的时候创建，用完就丢弃。
	每一级Bean.Dynamic只允许一个。

【2022/10/28】

------------------------------------------------------------------------------------------------------------------------------
tag v1.0.8 TableReadOnly BeanReadOnly ...; FollowerApply between conf+cs+net and java; Zega ...;
------------------------------------------------------------------------------------------------------------------------------
TableReadOnly ...
	table现在是module私有的，因为只读访问可能比较多，为了避免很多包装，提供只读接口给其他模块读取用。
	1. BeanReadOnly getter 名字，统一 ReadOnly 后缀。不可变变量还是不加ReadOnly了。
	2. Collections增加一个模板参数，现有三个模板参数。PMap2<K, V, VReadOnly> OK!
	3. 容器提供如 PListReadOnly 包装。
	   a) 修改操作不提供。
	   b) 内部Bean可修改是，访问内部Item需要得到BeanReadOnly。
Zege c#
	c# login bug; done?
	c# friends listener; done
	Topmost 重新实现：done
	1. 使用另一个LinkedMap存储，
	2. 有数量限制？读取的时候装载全部Node？
	3. 复杂度放在服务器：判断好友的时候用"或者的关系"判断两个LinkedMap。需要Review所有好友相关操作。
	c# MessageView; 1 先用控件版 2 自画版暂停开发 3 WebView 版未来考虑
	c# friend message;
	c# MessageFriend 管理数据。
	c# IMessageView, MessageViewControl 消息窗口接口和控件方式的实现。
	c# 未读红点算法确定。

------------------------------------------------------------------------------------------------------------------------------
tag v1.0.7 Table.DelayRemove; dynamic in collection; Zeze.Util.Cache; New LogDynamic
------------------------------------------------------------------------------------------------------------------------------
Table.DelayRemove 删除的实现。
dynamic is bean? 支持放入容器。@张路
LogDynamic：encode/decode 【大问题】
	1. 当整个Bean替换的时候需要传递Bean.Encode 
	2. 当Bean发生了编辑时需要传递LogBean。
	x. 需要像容器一样实现一个专有LogBean管理类。
Zege c#
	Mission.cs 增加错误处理Action; Done！
	c# create account;auth;login;friends; Done！

【2022/9/22】
------------------------------------------------------------------------------------------------------------------------------
tag v1.0.6 Timer; conf+cs+net; ServiceManager.OfflineNotify
------------------------------------------------------------------------------------------------------------------------------
Component.Timer 安全加强：
	1. fire是检查Index.ServerId确认自己是否拥有者。错误时cancel future，注意不是cancel timer。
	2. fire并发去重。
	3. Online Timer 记录版本号。并在fire时检查。
1. 调度使用的何种java底层机制
   基于Zeze.Table嵌入用户事务
2. 调度在分布式之间如何保证不会重复调度
   基于系列号
3. 调度丢失怎么处理的
   a) 基于事务，事务成功，Timer调度肯定也成功。
   b) ThreadPool.schedule，这个目前相信LoadTimer没有出错。
      或者下一次LoadTimer会恢复。要完全可靠的话就定时LoadTimer，
      当然需要自动忽略重复的TimerId。
4. 调度失败如何处理的
   这个调度是什么？
   a) 用户回调触发按刚才说的，除了异常，忽略其他错误。
   b) 或者这个和“调度丢失”一样的问题？
5. 调度超期(比如服务器down机重启)调度是如何进行的 -- simpleTimer cronTimer是否有不同
   a) 服务器宕机，其他服务器接管。
   b) 服务器正常重启，不接管（未实现）。
   c) simple,cron一样的。*现在simple已经改成每次ThreadPool.schedule(delay)，不使用它的period能力了。
6. 调度的创建和清理是如何做的, 清理如果失败了, 如果保证后续调度的非法性
   Timer.basic是持久的。
   a) 只有一个cancel接口，也是基于事务的。
   b) 如果ThreadPool.future没有清理，将发生上面的第2点。去重已经实现。
Component.Timer TimerArchOnline TimerGameOnline
ServiceManager.OfflineNotify.NormalClose
	正常关闭不发送server-down通知。
	【采用延迟发送通知的方案】额外规则：全系统停止时需要先停止ServiceManager.
直接暴露Zeze.Builtin.Collections.LinkedMap的数据结构给客户端。
ServiceManager::OfflineNotify

Zege
	GetPublicUserInfo,GetPublicUserPhoto 实现和linkd拦截处理;
	provider.module.binds.xml，模块默认hash(account); 
	创建账号和登录。
	Friend 完善：参数检查，权限相关。
	消息历史基本完工：保存和读取和设置已读。
	calculateMessageRange: eGetMessageFromAboutRead, eGetMessageFromAboutLast, eGetMessageToAuto, ...
	Friend 协议参数和数据库结构分开定义。
	管理员管理。
	Linkd hash(group) 改成 hash(group,departmentId)
	BFriend.Memo。
	群成员增加所属的部门。

conf+cs+net (+ts? +lua?)
	精简客户端，拷贝部分源码到自己的目录。
	1. conf+cs 系列化；使用gen命令输出系列化需要的源文件：gen -c ExportConf -ZezeSrcDir ../zeze 
	2. 拷贝Net目录；在项目中定义宏 USE_CONFCS，这样Net模块就不再依赖事务Bean和存储过程。
	3. 需要建立一个几乎空的 Zeze.Application，用来传递Config和避免修改Gen.exe。
	4. 拷贝 Zeze.IModule;Zeze.AppBase;Zeze.Config;Zeze.Util.ResultCode;Zeze.Util.Mission;Zeze.Util.Scheduler。
	   【这几个文件应该没有依赖其他东西，可以直接拷贝，需要确认。】
	%. FollowerApply: 实现增量日志

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.5 Certificate; Netty-Web More; Change Protocol Provider.Send To Rpc And Report Error;
------------------------------------------------------------------------------------------------------------------------------
Linkd重启，Server还在给它发送Send。此时，linkd发现Client不在线，补发LinkBroken缺少context的问题。
	*** 实际方案是 ***
	Send从Protocol改成Rpc，当Linkd发现发送失败时，通过Send.Result返回结果给Server并处理。

Netty-Web @张路
	1. close 确认 sending标志；遵守netty计数规则释放资源。
	2. KeepAlive & Idle Timeout。
	3. HttpExchange 不考虑多线程访问？
	4. 对上层掩盖连接，基于请求(HttpExchange)进行处理。

Zege 加密基础（基于证书）
	1. 任意CA签发的证书，默认提供一个不是权威的。
	2. 创建账号，上传public-key并签字，verify-sign之后，把pub跟账号绑定。
	3. 验证账号，签字随机串，服务器用绑定的pub验证签字。
	4. 增加绑定新的pub，同时用新旧pri签字，服务器都验证通过，绑定新增pub。同时不会作废旧的pub，用来读取消息历史。
	5. 小问题：x509 只支持rsa吗？
	6. 看看这个设想对不对，可不可实现。Self Sign Cert：不验证chain; 自己构建的 Linux Root Ca，可以发布根证书到服务器，可选验证chain; 权威Ca，需要验证chain。

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.4 Bean Construct With Parameter; Task.run auto detect transaction；Vector2 ... java support
------------------------------------------------------------------------------------------------------------------------------
Vector2 完善。@张路
Task.run 默认判断是否事务中，自动whileCommit。去掉Task.runWhileCommit。@张路
Bean 初始化构造函数（varid构造改成方法初始化，仅给内部使用）@张路

【2022/8/15】

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.3 Netty-Web；Task；AsyckSocket.closeGracefully
------------------------------------------------------------------------------------------------------------------------------
Netty-Web-File
AsyncSocket 如果outputbuf不为空，关闭时增加一个closing状态，等待全部写完然后自动关闭。
	closing状态不准再写入新数据。closing状态连接从Service中注销（这个需要权衡）。
	closeGracefully();
	哦，从service中去掉，外面就看不到了，这样closing状态可以省略（但是可能有地方记住了socket的引用，
	这样还需要提前触发原来的OnSocketClose的回调）。
	最终的结果就是连接已经不再可用，仅仅等待flush完成或者超时，真正关闭。
	考虑一下。应用得到OnSocketClose，但是连接还在写数据，可能会造成点小麻烦。应用层如果要时序的话。细节还是有几点。
	【closeGracefully还是提前从Service中注销并且触发OnSocketClose，不引入closing状态】
RedirectBase.RunVoid 前面的if分支漏了return
Netty-Web see zeze.docx::Web（Netty）
	Netty-Web 生命期管理规则。
	1. Exception HttpServer.java::Handler::exceptionCaught，来自Netty错误报告。
	    a) x = exchanges.remove(ctx);
	    b) 可配置的x.send500(cause) stacktrace。
	    c) netty-ctx.flush();
	    d) finally netty-ctx.close();

	2. HttpExchange.close() 用于请求正常处理完毕时关闭
		void close() {
			if (null != server.exchanges.remove(context)) {
				context.flush();
				context.close();
			}
		}
Task: void run; void runWhileCommit; future runUnsafe

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.2 ResetRootInfo While Redo; Simple Web; @DispatchMode
------------------------------------------------------------------------------------------------------------------------------
InitRootInfo 可回滚
	1. Transaction.WhileRedo
		内部用，这个行为不可预测，不开放给应用。

	2）Bean.InitRootInfoWithRedo
	// 这个方法仅在把用户创建的Bean加入到Zeze内变成受管理状态时调用。
	// PList2 PMap2 中所有的InitRootInfo替换成这个方法。
	// TableX 除了Load，GetOrAdd之外的主要是外部传入的Value的InitRootInfo替换成这个方法。
	public final void InitRootInfoWithRedo(Record.RootInfo rootInfo, Bean parent) {
		InitRootInfo(rootInfo, parent);
		Transaction.WhileRedo(ResetRootInfo);
	}

	3）Bean.ResetRootInfo
	private void Bean.ResetRootInfo() {
		RootInfo = null;
		Parent = null;
		// 需要生成一个新的，区别是去调用ResetRootInfo。
		// 这个不能重用InitRootInfo。
		// 看看还有什么更简单的办法。
		ResetChildrenRootInfo(rootInfo);
	}

	4）分析
	   a）
	   昨天的Log方式，本来想的是能对将要被管理的Bean的并发有一定的很受限的保护。
	   现在WhileRedo方式，原则上不对自己新建的Bean又传递给多个存储过程的情况进行保护了。
	   保护不完。
	   b）
	   ResetRootInfo 是否会导致树里面的分支重复重置？
	   由于Redo的时候，Log没有Commit，新加入容器的Bean还没有生效，我认为是不会重复重置的，但对这个情况需要确认。
	   即使重复重置，由于都是简单的set null，也不会有致命问题。
	   大家分析看看。
	   c）
	   原则：
	   WhileRedo方式更加有的放矢，即只解决传入的Bean重做的时候RootInfo没有重置倒是重做失败的问题。
	   不进行功能扩展了。

@DispatchMode
	这是一个协议处理函数的注解，用来控制协议的调度方式（仅用于Java）：
	•	在普通线程池中执行。默认是这种。
	•	在重要线程池中执行。
	•	在调用者线程执行。
	协议的线程调度方式除了用这个注解单独控制。还可以在Zeze.Net.Service子类中重载DispatchProtocol,DispatchRpcResponse等控制。
	重载会覆盖默认实现，优先级比注解高。默认实现按注解方式调度协议的执行。

Http In Linkd（java基于HttpServer或者更高级的包装类-感觉有新的了）
	GET 马上关闭InputStream。
	POST 已知Content-Length，记录已读取长度，比较Length，在读够时马上设置Finish，避免判断eof还需要读取一次(read==-1）。
	BUG Server.HttpExchange 没有关闭。
	WAINING Linkd.CloseOutputStream 多调用了一次。
	a) 去掉json,query对path的入侵
	b) 流支持
	c) HttpExchange，HttpServlet
	简单的Web服务器，侧重和Server的交互。逻辑由Server实现，Linkd只管转发。
	1. 简单查询(Request,Response)
	   是否KeepAlive由Http协议自己支持，上层只处理简单查询。
	   用途，在线管理系统。
	2. WebSocket，不是很了解，需要调研。关键：linkd是否需要侵入管理这个长连接。
	   长连接应用。
	3. 少量文件的下载
	   提供js文件下载，用来实现基于js的交互系统。
	   可以利用js(ts.ByteBuffer)实现Zeze.Protocol.Encode/Decode。
	4. Linkd 本来是全透明的，所有请求转发给Server即可。
	   为了某些系统中，Server不包含Auth信息，有专门的Auth服务器提供验证服务。
	   需要Linkd可以Auth请求，所以定义一个Auth的Handler用于这种情况。
	   这个Handler通过回调处理，回调不是必要的。
	5. 多WebApp支持。url-path的第一级为appname；需要传递url-path给Server；
	   每个WebApp包含自己的Auth？、Session，Servlet注册。
	   /webappname/servletpath.../query[.serverid]
	   /webappname/servletpath.../json[.serverid]
	   /webappname/servletpath.../queryauth[.serverid]
	   /webappname/servletpath.../jsonauth[.serverid]

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.1 AchillesHeelDaemon.ProcessDaemon & RelativeRecordSet.FlushSet
------------------------------------------------------------------------------------------------------------------------------
Immediately TableX::Load 立即保存。
Also Delete OldTable When Record Deleted 【in transaction】
AchillesHeelDaemon.ProcessDaemon for c# 重新实现一次当作review。【张路】
	MemoryMappedFile 未映射到磁盘上的现有文件的内存映射文件
	Mutex 跨进程锁，不需要用文件锁。
	UdpClent UDP，感觉这个是比较新的高级包装，不知道有没有UDPSocket的类。SocketError.TimedOut
	exec 还不知道用什么，由于c#运行环境不大一样，可能比较特殊。
TableCache Checkpoint 时机修改；java 不捕捉 sleep 异常，此时一般是程序退出；while 增加 App.isStart() 判断。
CheckpointMode.Table.Flush 在后台数据库的一个事务内提交多个rrs。【RelativeRecordSet.FlushSet】
Arch.Online Login+Logout 中间补充触发一个Logout事件?
	程序退出的时候怎么办？难道也要补？还有程序异常退出呢？
	由于实现可靠的Login+Logout匹配难度太大，
	逻辑还是需要处理Logout丢失的问题：一般在处理Login时发现上一个还没有Logout，自动完成相应处理。
checkpoint concurrent：Config.CheckpointModeTableFlushConcurrent
DatagramSocket Test
Exec Test
AchillesHeelDaemon：安全级别从jvm级别提升到操作系统。保留线程守护，增加进程守护。两个守护兼容：
	gs启动的时候检查mmap，发现自己是daemon启动的，就开启进程守护（向mmap报告和读取命令），否则还是原来的线程守护。

【2022/7/15】

------------------------------------------------------------------------------------------------------------------------------
tag 1.0.0 Stable? ^_^
------------------------------------------------------------------------------------------------------------------------------
Bean 依赖环检测。允许容器依赖环。
TableX.FlushWhenReduce 去掉回调方式，去掉Period支持（直接抛异常）。
raft.agent 永远尝试会造成大量服务不可用风险。
java Remove ServiceInfo.LocalState
1. BUG，ReduceInvalidAllLocalOnly 没有Flush。
2. BUG，TableX.Load 发现 Invalid 再去Acquire并Storage.Load时，如果本地记录是脏的，数据就会被覆盖。
   刚才TableX.Load的问题造成的可能原因分析：本地数据被Daemon.Release，是没有刷新到后台的，
   如果中间重新连上Global就会出现这个情况。但奇怪的是Daemon在你跑测试的时候是没有在工作的。
   这点的其他可能原因你也分析一下？
   虽然补丁好像可以Load时，if (!Record.Dirty) Storage.Load；但这个没有找到真正原因前，这个补丁有点危险。
   【修改：Reduce的时候，锁内执行Flush】

RedirectHash & RedirectAll & ChoiceHash - 单点数据分块支持与一致性Hash算法修改（原方案有问题：数据分块不能在服务器选择之后保持独立性）
	DataConcurrentLevel：数据分块数量。
	1. DataConcurrentLevel大于1 服务器选择：
	var ha = hash(account);
	var di = ha % DataConcurrentLevel; // account被分成Level个集合，每个集合访问一块数据
	var h = hash(di); // 不再考虑原始hash，参见后面第2.点。
	var server = ConsientHash(h);
	问题：
	   DataConcurrentLevel个数据块的访问是不是被分割成独立集合，每个集合在一个server内访问？
	2. DataConcurrentLevel=1服务器选择。
	var ha = hash(account);
	var server = ConsientHash(ha);
	问题：
	   相同的account在一个server上。这个显然没问题了。
ServiceManager.Agent Remove ServiceInfo.LocalState
【重大BUG】 即使锁内。Record.Global.State 可能没有提升到需要水平。需要重新_check_。
一致性hash负载分配算法, 【c# 没有TreeMap.tailMap。】
Table.WalkKey
Global-Server错误码分析
1. Warning
global 统计增加了Acquire和Reduce ResultCode的统计, GlobalRaft跑Simulate时,Acquire出现过以下失败情况:
 public static final long Exception = -1;
 public static final long RaftRetry = -15;
 int AcquireShareDeadLockFound = 21;
 int AcquireShareAlreadyIsModify = 22;
 int AcquireModifyDeadLockFound = 23;
 int AcquireModifyAlreadyIsModify = 25;
 int AcquireShareFailed = 26;
 int AcquireModifyFailed = 27;
2. Fatal
ERROR [] Table: RocksRaft Process Exception
java.lang.IllegalStateException: CacheState state error
 at Zeze.Services.GlobalCacheManagerWithRaft.AcquireShare(GlobalCacheManagerWithRaft.java:188)

【2022/6/11】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.9 Random Sleep For Global-Dead-Lock and Too-Many-Try & Global Restart ...
------------------------------------------------------------------------------------------------------------------------------
【TryWaitFlushWhenRecude 去掉啦】
Too Many Try: Fresh机制下由Global提供排队方案草稿：
  1. Server发现本地Fresh，拒绝Reduce。
  2. Global发现由于Fresh的拒绝，把申请者加入队列。
  3. Server把set Fresh=false时，发送通知给Global。
  4. Global收到Fresh==false通知，选择队列中的一个申请者开始处理。
  5. Global-Fresh队列管理。
     需要定时轮询的方式启动队列中的请求进行重做，防止Fresh=false通知丢失。
     请求总超时管理按一般请求超时处理。
     问题：请求第一次来的时候要不要判断Fresh队列不为空，然后马上加入队列。
  【死锁检测忙等问题】
     由于死锁检测必须返回结果，没法使用队列，所以这个问题不好解决。
     死锁检测原来的忙等解决方案是：TryWaitFlushWhenRecude，但仍然存在一个忙等窗口：
     当一个申请在进行过程中，CacheState还没有更新时，忙等仍然存在。
  【总结】
     用随机延迟一起解决Fresh排队和死锁检测忙等，上面的Fresh队列也不实现了。
-------------------------------------------------------------------------------------------
Arch：模块默认订阅类型设置为，SubsribeTypeSimple。（准备以后改成一致性hash算法）。
Global宕机：Server重连发送ReLogin，此时新启动的Global需要拒绝ReLogin，然后Server释放本地所有锁，重新发Login才能登录。
Gen: transient 应用到所有版本。
Too Many Try: Fresh机制下由Global提供排队方案草稿：
  0.【先采用临时方案】Server在RedoAndReleaseLock时随机Sleep延迟。

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.8 AchillesHeel & Handshake & Too Many Try
------------------------------------------------------------------------------------------------------------------------------
Handshake 是否加密可以配置。默认不加密。
AsyncSocket.VerifySecurity 在 CHandshakeDone处理时调用一次。不再需要在DispatchProtocol时调用。
Global错误处理：GS增加AchillesHeelDaemon，申请token（特别的keepalive）机制，本地释放锁超时，如果稍有不正常，就自杀。
too many try: 从Global得到锁以后，确保本地至少用过一次（事务成功），才允许Reduce。
Global-Server 错误恢复测试。1. Server 强制杀掉，8秒内重启。2. Server 强制杀掉，Global一定时间后回收记录锁。
Java Apply Zeze.Transaction.Logs

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.7 Java TableCache SoftReference Fix Bug Timestamp Value Access Order
------------------------------------------------------------------------------------------------------------------------------
Global错误处理：GS增加AchillesHeelDaemon，申请token（特别的keepalive）机制，本地释放锁超时，如果稍有不正常，就自杀。【草稿】
LinkedMap.BLinkedMapNodeValue 里面保存了key，但是walk接口没有返回，需要在dynamic里面再次定义。【callback返回key(id)，而不是nodeid】
LinkedMap.GetOrAdd
Zege 框架搭建完成。
java ServiceManager.AgentClient.DispatchProtocol Run In IO-Thread。
java Zeze.Applicate.deleteDirectroy: while(exist) { delete() }

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.6 zege start & c# raft ready
------------------------------------------------------------------------------------------------------------------------------
简介
	一个简单IM系统，支持大量好友，大量群成员。
目的
	用来验证zeze消息发送转发能力。
语言
	Server=java，Robot=java，Client=???
详细
	. 基于账号（不是Roleid）
	. 相同账户允许重复登录。
	. 给群发送消息使用RedirectHash。
	  比如有1000台server，那么群成员大概率平均分布，那么每个成员发送消息广播时，对群列表的利用率极低。
	  使用hash(group.Id)把群的广播请求固定分配到某台server上，提高群成员列表的利用率。
	  缺点是需要转发一次消息，但相当合理。
	. 大量群成员一起说话是没法聊的。所以实际上当群成员超过一定量（比如1000）时，需要分目录。
	  最终群成员被组织到一个部门树中。每个部门（包括根）都有自己的成员列表，限定数量内允许聊天。聊天不包含子部门。
产出
	Zeze.Collections.Tree
可能
	元宇宙实现一个基于RoleId的客户端内的好友系统，意义不大，应该独立成一个系统。
	可以考虑把这个测试程序发展成元宇宙的好友系统。以后提供unity内的client,以及android,ios,等等等...
	另外元宇宙server端需要访问好友系统，则通过server-server接口。
代号
	"Zege"，泽哥的意思

c# raft BUG: Zeze.Raft.LogSequence:849行TryAdd失败【张路找到，异常导致LeaderAppendLogs没有Rollback，然后在关闭Raft的时候，并发的还在处理中请求进入锁导致失败】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.5 c# ready(except raft)
------------------------------------------------------------------------------------------------------------------------------
1. raft 异步测试【未解决TryAdd失败BUG】
2. Global With Raft 异步测试【未进行】
3. 查找所有Wait并确认【Done】
4. Net Full Async【Done 但没有达到Global可以直接在DispatchProtocol里面await的目的】
5. Rewrite Scheduler【简单处理一下，使用的地方比较多，先这样啦】
6. UnitTest TestBag没过(呼叫肖丽杨)。

ServiceManager.ServiceInfo.Identity 编码：'@'开头为string，否则为int。Identity排序如果int按int的大小排序。
java ASYNC GlobalWithRaft Question：1. Transaction.Current is ThreadLocal？2. try ... finally? 3. exception? 【决定使用虚拟线程】

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.4 Online.ReliableNotify & Global.LruTryRemoveCallback
------------------------------------------------------------------------------------------------------------------------------
ReliableNotify - Sample(Zezex).client: 客户端可以延迟确认，如果发现Index不匹配，可以发送确认Rpc并且带上Sync标记进行重新同步。
Global.RocksRaft.LruTryRemoveCallback

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.3 inherit bean (conf+cs only)
------------------------------------------------------------------------------------------------------------------------------
1. bean继承实现
   【注意】class B : A; List<A>中被放入B时，Decode成A或者失败或者Encode报错。
   【注意】继承要实现动态，必须配合dynamic使用。如，List<dynamic:A>这样里面可以放A及A的子类，可以被正确encode/decode。

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.2 Gen: new type format; collection can hold dynamic type now
------------------------------------------------------------------------------------------------------------------------------
1. 新的模板参数声明格式
   <variable id="1" name="ListInt" type="list[int]"/>
   <variable id="2" name="SetInt" type="set[int]"/>
   <variable id="3" name="MingIntInt" type="map[int,int]"/>
   # 兼容旧的key，value声明方式，同时指定将抛异常。
2. dynamic 统一包含Bean的定义方式
   <variable id="1" name="Dynamic" type="dynamic" value="bean1,bean2">
      <value bean="bean3"/>
   </variable>
   改成
   <variable id="1" name="Dynamic" type="dynamic">
      <value bean="bean1"/>
      <value bean="bean2"/>
      <value bean="bean3"/>
   </variable>
   直接在variable的属性value中声明方式不再支持，统一在包含的element中声明。
3. dynamic 指定基类&可以放入容器中
   【基类即Bean将实现继承，仅在dynamic中才支持声明基类，下面是例子】
   【继承实现将有 @张路 完成，目前仅完成声明基类的解析】
   【解析基类是所有版本的，计划具体实现仅用于platform="conf+cs"，由张路决定】
   <variable id="1" name="ListInt" type="list[dynamic:BBase]"/>
   <variable id="2" name="SetInt" type="set[int]"/> set不支持包含dynamic，特别放这里说明一下
   <variable id="3" name="MingIntInt" type="map[int,dynamic:BBase]"/>
   <variable id="4" name="BeanWithBase" type="dynamic:BBase"/>

------------------------------------------------------------------------------------------------------------------------------
tag 0.9.1 Java TableCache SoftReference 2022.5.13
------------------------------------------------------------------------------------------------------------------------------
TableCache增加一级RocksDb的缓存，不容易受限于内存。Java SoftReference<T>.
TableCache.Clean 整体考虑。
<<<
TableCache 原来想增加一级基于RocksDb的巨大缓存，由于这个缓存有不少状态需要快速访问，完全增加一级效率不够高，所以决定做个简化版本。
1. TableCache.Lru 还是拥有所有配置的容量内的记录，总是持有必要的状态数据。
2. 记录的用户数据使用 SoftReference 引用。
3. 记录本身还是按旧的机制管理生命期和状态。需要的时候会同步RocksDb。
4. SoftReference 回收的时候，保存一份到RocksDb中。【原子问题需要考虑】
5. SoftReference 不存在，从RocksDb装载。【原子问题需要考虑】
6. RocksDb虽然是持久化到硬盘的，但是重启会全部删除。
9. 使用RocksDb保存被GC的用户数据这个特性做成可选（又是需要if判断）?【没有实现】
*. Cache 实现草稿
【一】
private KV<Record1<K,V>, V> TableX.Load(K key) {
    ...
    if (r.getState() is right) {
        var strong = r.Soft.get();
        if (null == strong && false == r.getDirty()) { // dirty 时意味着应用做出了修改但还没保存，此时不需要load
            strong = RocksDb.get();
            r.Soft.set(strong);
        }

        // strong需要返回，不能从r.soft里面再次获取
        // 使用Load的地方：
        // 1. Transaction.get等。需要把strong记到事务的RecordAccessed中，在事务结束前都不能触发soft回收。
        // 2. selectDirty。可以事务外使用，使用者自己管理strong生命期。
        return KV.Create(r, strong);
    }
    ...
    // load from storage
    var strong = TStorage.Find(key, this);
    RocksDb.put(); // 【原则】保持Rocks和后台数据库一致。
    r.Soft.set(strong);
    ...
    return KV.Create(r, strong);
}

【二】
Record.setDirty(bool value) {
    Dirty = value; 【原来的】
    StrongRef = value ? soft.get() : null; // 脏数据在记录内保持一份强引用。
    // 由于记录不存在时，StrongRef可为null，所以原来的bool Dirty不能使用 StrongRef != null 代替。
    // 需要分成明确的两个变量。
}

【三】
RecordAccessed 增加 Bean StrongRef，保存Load的返回值里的bean引用。

【四】
public void Record1.Flush(Database.Transaction t) {
    ...
    if (null != snapshotValue)
        RocksDb.put();
    else
        RocksDb.Remove();
}

【五】
public void Record1.SetDirty() {
    ...
    case Immediately:
        RocksDb.put(); // Immediately 模式需要在这里保持Rocks和后台数据库一致。它走不一样的Flush流程。
        break;
}

【六】
private boolean TableCache.Remove(Map.Entry<K, Record1<K, V>> p) {
    ...
    RocksDb.remove();
    // 从cache中删除，也需要删除持久化的，这个违背了【原则：RocksDb和后台数据库一致】，
    // 但是不删除，会导致长期运行，本地cache一直积累。
    return true;
}

【七】
public void Record1.Encode0() {
    ...
    snapshotValue = StrongDirtyValue != null ? getTTable().EncodeValue((V)StrongDirtyValue) : null;
    // StrongDirtyValue 最新的value。
}

【原则】
1. RocksDb和后台数据库一致。
2. 事务内访问的记录不能被回收。
3. selectDirty返回的strongref需要使用者自己管理。

>>>

【2022/5/11】

Global 性能测试
------------------------------------------------------------------------------------------------------------------------------
tag 0.9.0 java ready
------------------------------------------------------------------------------------------------------------------------------
TableKey,GlobalTableKey TableName -> TableId
Java New Changes: 1. Gen 2. Collections 3. Log 4. Changes & remove CreateChangeVariableCollector 5. Transaction & Savepoint
Java Global Performance: 【张路】26w/s 200M带宽
3. Test TestGlobal Simulate 异步测试【已经通过测试了 2022.5.9】
把 RocksRaft Changes 应用到 Zeze 中，让 Zeze 实现Bean任意级别的更新。
仅支持整个Bean的订阅。
log factory 问题。（不同步到其他进程没有这个问题）
动态订阅。add listener和notify原子问题。【收集和通知一致，不会出现收集丢失。】
Game.Bag Listener
Online Account （c#）
Global java 异步化： TaskQueueAsync 任务需要参与到队列的推进。全异步和RocksRaft.Transaction.ThreadLocal问题，需要自己实现一个类似AsyncLocal的机制。
StableLinkSid Done(Need Test)
StableLinkSid Prepare：分离LinkName,LinkSid到独立表中。
Arch remove ProviderSessionId；Rename ProviderId to ServerId
Online Test 【肖丽杨】Java
RocksRaft Collection.List LogList
【张路已完成】OpLogs=List<OperateLog>。list中的Bean更新规则：Encode的时indexOf所有的Changed找到索引，Apply=list.get(index).Apply(beanLog)。
2. c# 1) LoadReporter. 
3. java 1) LoadReporter. 
1. Online Memory Table 可以存储在线相关数据。
   功能
   a) Local.Online.Count
   b) Foreach Local Online
   c) LocalData Set Get
   维护 memory Table 准确的机制
   a) 本机正常Login/Logout/LinkBroken
   b) 本机Logout/LinkBroken丢失或迟到，而已经在其他机器上Login，此时需要Redirect过来。
   c) Redirect丢失，本机需要一个机制遍历TableCache，慢慢检测并清除Memory中登录状态无效的数据。
   事件
   Logout事件需要带上当前Memory表中存的用户数据。
1. c# Arch RedirectAll & Test
2. c# Game.Rank TODO GetRankAll Test
1. Zezex Onlines TransmitInProcedure 需要重写。需要改成使用ProviderDirectService.ProviderByServerId。
1. FewModifyList
2. FewModifyMap
c# RedirectGenMain 内建模块Redirect生成。
Java RedirectGenMain 内建模块Redirect生成。
Java 2) Online Logout Check Not Owner.
Java 3) ProviderImplementWithOnline
Java 4) ProviderDirectWithTransmit
c# 2) Online Logout Check Not Owner.
c# 3) ProviderImplementWithOnline
c# 4) ProviderDirectWithTransmit
Global 死锁. lock(CacheState) lock(CacheHolder)之间互相依赖。
	3月份调整代码，试图对同一个session(每个serverId对应一个，即CacheHolder)进行互斥同步时的改动引进的bug。
	去掉了 lock(session)，恢复成原来的 tryBind，tryUnbind里面lock，不持有。仔细想了一下。
	互斥由tryBind,tryUnbind的逻辑保证，只允许一个serverid的实例的session前进到下一步，其他都失败。
Builtin Module UnRegister 实现。
c# Zeze.Game.Bag
c# Zeze.Game.Rank
c# Zeze.Game.Online
Java Zeze.Game.Rank Test【张路】
Java Zeze.Game.Bag Test【王鹏安排】
Java Zeze.Game.Online 【张路】
Java Zeze.Game.Bag
Java Zeze.Game.Rank
Redirect 支持异步实现。【Java张路】 c# RedirectAll 错误处理。
c# Arch : redirect Hash & Server Test Ok
c# Arch Redirect Hash & Server async ready.
c# Collections Queue LinkedMap
c# Component DelayRemove AutoKey RedoQueue RedoQueueServer
Java Arch Test：RedirectToServer,RedirectHash Done
ServiceManager.Agent lock 模式：改成全局锁Agent。单线程化。回调也在锁内执行。【放弃，锁内回调风险太高】
ServiceManager: Provider之间连接成功的时候，Pending还没到达。
ServiceManager.ReadyCommit模式时，订阅启动全新广播。

【2022/4/11】

Load 移到 Zeze.Arch 里面，里面使用的MyConfig相关配置移到LoadConfig中。【使用OnSetServerLoad，Game.Load复用暂不考虑了】
Java Arch Callback在不同Redirect模式下的限定和检查
CommitServiceList,ReadyServiceList 不发送整个列表，仅发送系列号。
问题：Java Arch ServiceManager ReadyCommit 依赖Provider之间的连接，但是连接又依赖Indentity-List-Ready。【暴露Pending状态的列表】
ProviderSession 增加 Set(ServiceName,Identity) OnSocketClose 时 foreach (var (s,i)) SetServiceIdentityReadyState(s, i, null);
SetServiceIdentityReadyState(+ServiceName, identity, state);【误会，这个定义在SubscribeState里面的，不需要ServiceName了】
Linkd-Provider之间的连接建立比Provider-List通告早，需要查询得到。【没问题，异步问题已经处理。当连接任何时候准备好，调用SetServiceIdentityReadyState设置进去】
java Arch: ModuleRedirect 重构。
	【左尧完成Java了？】Zezex.ModuleRedirect 增加 TransactionLevel 注解配置。
	Zezex.ModuleRedirect 去掉依赖Session生成hash模式；RunMyMethod去掉mode；
java Arch: 重构 Provider：分为 Provider(linkd-gs),Provider2(gs-gs)。预计负载算法还需要公用。
Load ServiceManager 新增按按Ip-Port组织的订阅和通告。
Load 更新。
RedoQueue Client 【未测试】
RedoQueue
{
	1）存储：QueueId。 RocksDb<TaskId, Full_Encoded_Net_Rpc> 持久化的。
	2）Task.Id long 递增 Rpc
	Zeze.ServerApp
	1) zeze.table<QueueId, LastTaskId> 记住已经同步的最后的任务id，
	2) 功能：每个QueueId，for (LastTaskId, end) { Run(task); zeze.table.LastTaskId = task.Id; }
	* 特性：允许 Zeze.ServerApp 回档，回档以后，从旧的LastTaskId开始重做任务。
}
Zeze.Component dynamic bean动态增加类型的能力。
LockAsync 单元测试。关键：TryEnterXXXLock。
Queue
GCTable(每个ServerId一个Queue), rename to DelayRemove
Component.AutoKey
java LinkedMap dynamic 动态注册问题。
换换脑子，写一个java版基于KV的LinkedMap
async Connector GetReadySocket WaitReady 
GlobakWithRaft java test【张路】【基本可用了】
GlobalAgent NormalClose 超时设置。必须加大或者无限等待。
zeze async await test。remove SimpleThreadPool!
database 异步测试
ServiceManager 异步化
TestCheckpoint 整个跑会失败，单独一个一个测试跑成功。【加了async，没有await】
async TestCheckpointModeTable 直接运行 Trans 目录会出错，单个或者选择开始的几个运行没问题。【AsybcLocal<Transaction>重用有问题，去掉重用】
rocksraft 异步测试【raft还有bug，但这个能测试通过】
Raft.AppendLog 加一个try catach，所有的内部错误都转换成RaftRetryException，这样就不会把内部异常漏给应用了。
AsyncRocksDb
AsyncExecutor
database 异步化 
Global With Raft 异步化
rocksraft 异步化
raft 异步化
Global 异步化
c# zeze 嵌套存储过程RunWhileRollback在外层事务Commit时需要处理的问题。还有按调用顺序回调的问题。
	Savepoint 成员变量 CommitActions RollbackActions
	Savepoint.Commit(nest) CommitActions.AddAll(nest.CommitActions);
	Savepoint.Rollback(nest) CommitActions.AddAll(nest.RollbackActions); RollbackActions.AddAll(nest.RollbackActions);
	Transaction.FinalCommit() foreach (var a in LastSavepoint.CommitActions) a.trigger();
	Transaction.FinalRollback() foreach (var a in LastSavepoint.SavedRollbackActions) a.trigger();
zeze async await compile ok!
Raft.Shutdown 先关闭网络，有错误也不返回了。
TaskOneByOne 重构，新增支持调用异步存储过程和异步协议处理。
Global PulseAll 必须，需要全部等待在死锁检测的线程全部再来一遍，否则仍有可能死锁。
GlobakWithRaft java compile ok!
RaftLog.DecodeTermIndex 仅Decode两个内部变量，不包含应用日志。避免初始化循环依赖。
GlobalWithRaft c# test 1111
	CacheHolder 访问 Instance 是旧的代码，引用到旧的static上面了。
	AcquireModify Reduce Share 的时候，比如返回原来的事务才能修改数据。
	* 这点非Raft版本Global(c#&java)都改成返回主流程修改状态数据。
GloblWithRaftAgent c# WaitLoginSuccess
RocksRaft java
RocksRaft rrjava
GlobalRaft Agent.Initialize & Test
GlobalRaft Agent GetReadySocket() Login ReLogin	
GlobalRaft GlobalSerialId 问题解决初步想法：由RocksRaft提供AtomicLong实现，每个事务结束，
成功同步到其他节点。这个Global拿来区分记录申请次数，需要一直递增，可以跳着分配（浪费）。
细节：lock (Raft) { if (atomiclong.get() > lastAppendLog) doAppendLog; }

【2022/3/11】

Global 流程确认：独占排他性，Raft版本部分操作仅Leader有效?
Global NormalClose 需要锁定Session，释放所有锁，确保释放完之前新的服务器不会登录进来。【raft及非raft版本都需要考虑】
Global Cleanup 需要锁定，释放所有锁，这里无法通过lock(session)保护。
Global Login Bind以后，释放存在的锁，看来没有问题，需要确认。
Global ReLogin 不涉及所释放，能Bind成功就表示ReLogin成功，看来没有问题，需要确认。

GlobalCacheManagerWithRaft 关键Transient：CacheState.AcquireStatePending 仅在Leader上使用，不需要同步到Follower。
RocksRaft & rrcs GenTable OpenTable 提供模板化打开表格能力。
RocksRaft Gen Bean.Variable.Transient Attribute
RocksRaft Gen
	. Bean.Kind : "bean" "beankey" "rocks" "dynamic" ""
	. project platform add type: "internal+cs" "internal+java" 增加属性 IsInternal 仅把原来Gen/下的类生成到src空间下，src下的代码不生成。
RocksRaft Collection.Set
RocksRaft Raft.AppendLog
RocksRaft NestProcedureContainer Test
RocksRaft Simple NestProcedure Test
RocksRaft Edit Bean In Container
Raft.AppendLog Future Add Duplicate Index. Fatal!【观察不到了！】
c# Global 慢？【网络事件也和普通Task共享了一个线程池，造成rpc.result处理也排队的结果，等async解决】
RocksRaft 日志收集基本完工。
Raft.Test 只删除日志相关数据库。保留重复请求数据库。
Raft.UniqueRequestSet.Put 优化：先读取并检查状态，减少写操作。
Raft.UniqueRequest.Expired
Raft.Expired
Raft.AppendLog 带上当前Rpc.Result，当发现重复请求的时候返回
Raft.LogSequence.FindMaxMajorityLogIndex 新实现，不需要遍历Log。
Raft.LogSequence.FindMaxMajorityLog 里面的 ReadLog 优化掉。
1. Log.cs: logger.Fatal("truncate committed entries"); Fatal!【选举移动代码的BUG：Term在递增前使用】
Raft.Apply 分批进行，让其他操作有运行机会。解决启动时，apply整个日志锁住时间太长的问题。
Raft.State.Timeout 恢复状态模式。【不恢复，就轮询了】
RaftLog.ToString More Detail
Raft.Agent TryGetReadySocket 总是 null。【没有发现问题】
Net.Connector.OnSocketHandshakeDone Fail 原因。【没有发现问题】
Raft.Shutdown 的时候快速失败-Cancel在Future上等待的任务。【有时shutdown会很慢】
2. Raft.Vote Leader 第一个Hearbeat被拒绝;  导致不停的选举。
   SaveLog.RocksDb.Put 卡住导致超时？
3. Raft.Count 错误处理问题？请求已经被处理，但是结果丢失，重发请求发生了不会重做的异常，这会导致Count统计不正确。【Raft.AppendLog 检查LogSequence是否null】
Raft.Vote 优先级++++++++++++++++++++++++++ 初步考虑仅使用不同的延迟。RandomDelay + DelayPriority;
Raft.Agent 客户端卡住了? 【锁内 Env.Exit卡住了，导致OnTimer任务不停积累，最终线程数量巨大】
Raft.RocksDb.Open Try N Times
Raft.Vote 投票后推迟自己再次选举的时间，免得浪费。【现在代码注释掉了】
Raft.Log.FollowerOnAppendEntries 优化。
Raft.Log.Index 必须递增，去掉原来支持跳着分配的代码，并且在需要的地方增加错误检查。
Raft.Agent ActiveTime 重连功能删除，
Net.Connector 轮询重连，【恢复回状态检查实现，轮询改为10分钟的错误处理】
Net.Connector 轮询重连？以后恢复成连接断开才启动timer？先轮询，等raft稳定了再考虑。
Raft.Test 关闭2节点后，一直没有重启。【测试程序出错了】
